{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MUYang99/NOx-Time-Series-Prediction-Based-on-Deep-Learning/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5PqmM1Rnq2b"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector\n",
        "from keras.optimizers import adam_v2\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from scipy import stats, arange"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmVL6FcitgdG"
      },
      "source": [
        "### Import & process data\n",
        "df = pd.read_excel('d2.xlsx')\n",
        "df.columns = ['Date', 'NOx']\n",
        "df = df.dropna(subset=['NOx'])\n",
        "data = df[df.Date < '20151231']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SRsIAN56zSn"
      },
      "source": [
        "# Import data\n",
        "def load_data() -> pd.DataFrame:\n",
        "\n",
        "  df = pd.read_excel('d2.xlsx')\n",
        "  df.columns = ['Date', 'NOx']\n",
        "  df = df.dropna(subset=['NOx'])\n",
        "\n",
        "  return df"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gDWXSRK7ZfF"
      },
      "source": [
        "# MinMaxScaler \n",
        "# For speeding up the model fitting and improving the accuracy\n",
        "def minmaxscaler(data: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "  # nox = data.NOx.values\n",
        "  nox = data.values\n",
        "  nox = nox.reshape(len(nox), 1)\n",
        "  nox = scaler.fit_transform(nox)\n",
        "  nox = nox.reshape(len(nox),)\n",
        "  # data['NOx'] = nox\n",
        "  # data.columns = ['', 'NOx']\n",
        "\n",
        "  return nox"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQC5mKzr9c8n"
      },
      "source": [
        "# Build data set\n",
        "def build_dataset(data):\n",
        "\n",
        "  #data = data.drop([\"Date\"], axis=1)\n",
        "  X, Y = [], []\n",
        "  for i in range(data.shape[0]-n_in-n_out+1):\n",
        "    # X.append(np.array(data.iloc[i:i+n_in]))\n",
        "    # Y.append(np.array(data.iloc[i+n_in:i+n_in+n_out]))\n",
        "    X.append(np.array(data[i:i+n_in]))\n",
        "    Y.append(np.array(data[i+n_in:i+n_in+n_out]))\n",
        "\n",
        "  return np.array(X), np.array(Y)"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUeKjUSP8hih"
      },
      "source": [
        "# Split the train and validation datasets\n",
        "def split_data(x, y):\n",
        "  \n",
        "  x_train = x[:-n_val-n_out+1]\n",
        "  x_val = x[-n_val:]\n",
        "  y_train = y[:-n_val-n_out+1]\n",
        "  y_val = y[-n_val:]\n",
        "\n",
        "  return x_train, y_train, x_val, y_val"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7hHX3Tx-xrC"
      },
      "source": [
        "# Contruct the LSTM\n",
        "def build_lstm():\n",
        "\n",
        "  model = Sequential()\n",
        "  # model.add(LSTM(n_neuron, input_shape=(n_in, n_features)))\n",
        "  model.add(LSTM(n_neuron, input_shape=(n_in, n_features)))\n",
        "  #model.add(LSTM(200, return_sequences=False))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(n_out))\n",
        "  # model.add(Activation(\"sigmoid\"))\n",
        "  model.compile(optimizer=adam_v2.Adam(learning_rate=1e-4), loss='mae')\n",
        "\n",
        "  return model"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPb1V7hFuQxz"
      },
      "source": [
        "class RocAucMetricCallback(Callback):\n",
        "    def __init__(self, predict_batch_size=1024):\n",
        "        super(RocAucMetricCallback, self).__init__()\n",
        "        self.predict_batch_size = predict_batch_size\n",
        " \n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        pass\n",
        " \n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        pass\n",
        " \n",
        "    def on_train_begin(self, logs={}):\n",
        "        if not ('val_roc_auc' in self.params['metrics']):\n",
        "            self.params['metrics'].append('val_roc_auc')\n",
        " \n",
        "    def on_train_end(self, logs={}):\n",
        "        pass\n",
        " \n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        pass\n",
        " \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        logs['roc_auc'] = float('-inf')\n",
        "        if (self.validation_data):\n",
        "            logs['roc_auc'] = roc_auc_score(self.validation_data[1], self.model.predict(self.validation_data[0], batch_size=self.predict_batch_size))\n",
        "            print('ROC_AUC - epoch:%d - score:%.6f' % (epoch + 1, logs['roc_auc']))"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kiG_K9J_YgP"
      },
      "source": [
        "# Train the model\n",
        "def model_fit(x_train, y_train, x_val, y_val):\n",
        "    \n",
        "    model = build_lstm()\n",
        "    \n",
        "    my_callbacks = [\n",
        "        RocAucMetricCallback(),\n",
        "        EarlyStopping(monitor='roc_auc', patience=20, verbose=2, mode='max')\n",
        "    ]\n",
        "    history = model.fit(x_train, y_train, batch_size=batchsize, epochs=n_epochs, verbose=1, validation_data=(x_val, y_val))\n",
        "    plt.plot(history.history['loss'], label='train')\n",
        "    plt.plot(history.history['val_loss'], label='validation')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk8zo-LP6alF"
      },
      "source": [
        "n_in = 672\n",
        "n_out = 144\n",
        "n_features = 1\n",
        "n_val = 1\n",
        "\n",
        "n_epochs = 30\n",
        "batchsize = 128\n",
        "n_neuron = 150"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OzqI5iTAL3x"
      },
      "source": [
        "data = load_data()\n",
        "data = data[data.Date < '20151231']\n",
        "d1 = data.drop([\"Date\"], axis=1)"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJR3d2Z9on4L"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data = minmaxscaler(data)"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15NHPZneAih4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc8ab1ca-efe8-426a-84af-4de399d7387c"
      },
      "source": [
        "data_copy = data.copy()\n",
        "x, y = build_dataset(data_copy)\n",
        "x_train, y_train, x_val, y_val = split_data(x, y)\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "y_train = np.reshape(y_train, (y_train.shape[0], y_train.shape[1], 1))\n",
        "x_val = np.reshape(x_val, (x_val.shape[0], x_val.shape[1], 1))\n",
        "y_val = np.reshape(y_val, (y_val.shape[0], y_val.shape[1], 1))"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15716, 672, 1)\n",
            "(15716, 144, 1)\n",
            "(1, 672, 1)\n",
            "(1, 144, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY_jh-oPgP1N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 971
        },
        "outputId": "a28642f5-1c05-4a91-daf9-24f62f7e2b82"
      },
      "source": [
        "model = build_lstm()\n",
        "model = model_fit(x_train, y_train, x_val, y_val)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "123/123 [==============================] - 20s 149ms/step - loss: 0.1743 - val_loss: 0.1245\n",
            "Epoch 2/30\n",
            "123/123 [==============================] - 18s 146ms/step - loss: 0.1458 - val_loss: 0.1231\n",
            "Epoch 3/30\n",
            "123/123 [==============================] - 18s 146ms/step - loss: 0.1431 - val_loss: 0.1164\n",
            "Epoch 4/30\n",
            "123/123 [==============================] - 18s 145ms/step - loss: 0.1381 - val_loss: 0.1040\n",
            "Epoch 5/30\n",
            "123/123 [==============================] - 18s 147ms/step - loss: 0.1317 - val_loss: 0.1042\n",
            "Epoch 6/30\n",
            "123/123 [==============================] - 18s 146ms/step - loss: 0.1292 - val_loss: 0.1035\n",
            "Epoch 7/30\n",
            "123/123 [==============================] - 18s 145ms/step - loss: 0.1279 - val_loss: 0.1055\n",
            "Epoch 8/30\n",
            "123/123 [==============================] - 18s 146ms/step - loss: 0.1272 - val_loss: 0.1047\n",
            "Epoch 9/30\n",
            "123/123 [==============================] - 18s 146ms/step - loss: 0.1265 - val_loss: 0.1017\n",
            "Epoch 10/30\n",
            "123/123 [==============================] - 18s 146ms/step - loss: 0.1262 - val_loss: 0.1009\n",
            "Epoch 11/30\n",
            "123/123 [==============================] - 18s 145ms/step - loss: 0.1258 - val_loss: 0.1033\n",
            "Epoch 12/30\n",
            "123/123 [==============================] - 18s 148ms/step - loss: 0.1253 - val_loss: 0.1015\n",
            "Epoch 13/30\n",
            "123/123 [==============================] - 18s 147ms/step - loss: 0.1251 - val_loss: 0.1009\n",
            "Epoch 14/30\n",
            "123/123 [==============================] - 18s 146ms/step - loss: 0.1248 - val_loss: 0.1015\n",
            "Epoch 15/30\n",
            "123/123 [==============================] - 18s 145ms/step - loss: 0.1245 - val_loss: 0.1028\n",
            "Epoch 16/30\n",
            "123/123 [==============================] - 18s 146ms/step - loss: 0.1244 - val_loss: 0.1011\n",
            "Epoch 17/30\n",
            " 83/123 [===================>..........] - ETA: 5s - loss: 0.1243"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-169-b8c2c0f5fe11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-160-560849a03d9a>\u001b[0m in \u001b[0;36mmodel_fit\u001b[0;34m(x_train, y_train, x_val, y_val)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     ]\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FguhlLtgHHP"
      },
      "source": [
        "# Validation & visulization\n",
        "predict = model.predict(x_val)\n",
        "validation = scaler.inverse_transform(predict)[0]\n",
        "validation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDorV8pxshjJ"
      },
      "source": [
        "y_val = y_val.reshape(1,n_out)\n",
        "true = scaler.inverse_transform(y_val)[0]\n",
        "true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T32QmZ5VspGI"
      },
      "source": [
        "x = [x for x in range(n_out)]\n",
        "fig, ax = plt.subplots(figsize=(15,5), dpi = 300)\n",
        "ax.plot(x, validation, linewidth=2.0, label = \"predict\")\n",
        "ax.plot(x, true, linewidth=2.0, label = \"true\")\n",
        "ax.legend(loc=2);\n",
        "plt.grid(linestyle='-.')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf0sCsC3w_vO"
      },
      "source": [
        "MSE = mean_squared_error(true,validation)\n",
        "RMSE = np.sqrt(MSE)\n",
        "print('Test RMSE: %.3f' %RMSE)\n",
        "MAE = mean_absolute_error(true,validation)\n",
        "print('Test MAE: %.3f' %MAE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCgx9Pzgeq2t"
      },
      "source": [
        "##################################### Box-plot #####################################\n",
        "# fig = plt.figure(figsize = (10,6))\n",
        "# ax1 = fig.add_subplot(2,1,1)\n",
        "# color = dict(boxes='DarkGreen', whiskers='DarkOrange', medians='DarkBlue', caps='Gray')\n",
        "# d1.plot.box(vert=False, grid = True,color = color,ax = ax1,label = 'NOx data')\n",
        "\n",
        "# s = data.describe()\n",
        "# print(s)\n",
        "# print('------')\n",
        "# q1 = s['NOx'][4]\n",
        "# q3 = s['NOx'][6]\n",
        "# iqr = q3 - q1\n",
        "# min = q1 - 1.5*iqr\n",
        "# max = q3 + 1.5*iqr\n",
        "# print('IQR：%.3f，min：%.3f，max：%.3f' % (iqr,min,max))\n",
        "\n",
        "# ax2 = fig.add_subplot(3,1,3)\n",
        "# error = d1['NOx'][(d1['NOx'] < min) | (d1['NOx'] > max)]\n",
        "# data_c = d1['NOx'][(d1['NOx'] >= min) & (d1['NOx'] <= max)]\n",
        "# print('The number of outliers: %i' % len(error)) \n",
        "# plt.scatter(data_c.index,data_c,color = 'k',marker='.',alpha = 0.3)\n",
        "# plt.scatter(error.index,error,color = 'r',marker='.',alpha = 0.5)\n",
        "# plt.grid()"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46nvEHm6tFfC"
      },
      "source": [
        "##################################### Normal-distribution(3 sigma) #####################################\n",
        "# u = d1['NOx'].mean() \n",
        "# std = float(d1['NOx'].std())\n",
        "# stats.kstest(d1['NOx'], 'norm', (u, std))\n",
        "# print('Mean：%.3f，Std：%.3f' % (u, std))\n",
        "\n",
        "# sigma = 3\n",
        "# fig = plt.figure(figsize = (10,6))\n",
        "# d1.plot(kind = 'kde',grid = True,style = '-k',title = 'Density curve')\n",
        "# plt.axvline(sigma*std,color='r',linestyle=\"--\",alpha=0.8) \n",
        "# plt.axvline(-sigma*std,color='r',linestyle=\"--\",alpha=0.8)\n",
        "\n",
        "# error = d1['NOx'][np.abs(d1['NOx'] - u) > sigma*std]\n",
        "# data_c = d1['NOx'][np.abs(d1['NOx'] - u) <= sigma*std]\n",
        "# print('The number of outliers: %i' % len(error))\n",
        "# ax1 = fig.add_subplot(3,1,1)\n",
        "# plt.scatter(data_c.index,data_c,color = 'k',marker='.',alpha = 0.3)\n",
        "# plt.scatter(error.index,error,color = 'r',marker='.',alpha = 0.5)\n",
        "# plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}