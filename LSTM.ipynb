{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MUYang99/NOx-Time-Series-Prediction-Based-on-Deep-Learning/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5PqmM1Rnq2b"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SRsIAN56zSn"
      },
      "source": [
        "# Import data\n",
        "def load_data() -> pd.DataFrame:\n",
        "\n",
        "  df = pd.read_excel('d1.xlsx')\n",
        "  df.columns = ['Date', 'NOx']\n",
        "  df = df.dropna(subset=['NOx'])\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gDWXSRK7ZfF"
      },
      "source": [
        "# MinMaxScaler \n",
        "# For speeding up the model fitting and improving the accuracy\n",
        "def minmaxscaler(data: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "  nox = data.NOx.values\n",
        "  nox = nox.reshape(len(nox), 1)\n",
        "  nox = scaler.fit_transform(nox)\n",
        "  nox = nox.reshape(len(nox),)\n",
        "  data['NOx'] = nox\n",
        "\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQC5mKzr9c8n"
      },
      "source": [
        "# Build data set\n",
        "def build_dataset(data):\n",
        "\n",
        "  data = data.drop([\"Date\"], axis=1)\n",
        "  X, Y = [], []\n",
        "  for i in range(data.shape[0]-n_in-n_out+1):\n",
        "    X.append(np.array(data.iloc[i:i+n_in]))\n",
        "    Y.append(np.array(data.iloc[i+n_in:i+n_in+n_out]))\n",
        "\n",
        "  return np.array(X), np.array(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUeKjUSP8hih"
      },
      "source": [
        "# Split the train and validation datasets\n",
        "def split_data(x, y):\n",
        "  \n",
        "  x_train = x[:-n_val-n_out+1]\n",
        "  x_val = x[-n_val:]\n",
        "  y_train = y[:-n_val-n_out+1]\n",
        "  y_val = y[-n_val:]\n",
        "\n",
        "  return x_train, y_train, x_val, y_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7hHX3Tx-xrC"
      },
      "source": [
        "# Contruct the LSTM\n",
        "def build_lstm():\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(n_neuron, input_shape=(n_in, n_features)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(n_out))\n",
        "  model.compile(optimizer=Adam(learning_rate=1e-4), loss='mae')\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPb1V7hFuQxz"
      },
      "source": [
        "class RocAucMetricCallback(Callback):\n",
        "    def __init__(self, predict_batch_size=1024):\n",
        "        super(RocAucMetricCallback, self).__init__()\n",
        "        self.predict_batch_size = predict_batch_size\n",
        " \n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        pass\n",
        " \n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        pass\n",
        " \n",
        "    def on_train_begin(self, logs={}):\n",
        "        if not ('val_roc_auc' in self.params['metrics']):\n",
        "            self.params['metrics'].append('val_roc_auc')\n",
        " \n",
        "    def on_train_end(self, logs={}):\n",
        "        pass\n",
        " \n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        pass\n",
        " \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        logs['roc_auc'] = float('-inf')\n",
        "        if (self.validation_data):\n",
        "            logs['roc_auc'] = roc_auc_score(self.validation_data[1], self.model.predict(self.validation_data[0], batch_size=self.predict_batch_size))\n",
        "            print('ROC_AUC - epoch:%d - score:%.6f' % (epoch + 1, logs['roc_auc']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kiG_K9J_YgP"
      },
      "source": [
        "# Train the model\n",
        "def model_fit(x_train, y_train, x_val, y_val):\n",
        "    \n",
        "    model = build_lstm()\n",
        "    \n",
        "    my_callbacks = [\n",
        "        RocAucMetricCallback(),\n",
        "        EarlyStopping(monitor='roc_auc', patience=20, verbose=2, mode='max')\n",
        "    ]\n",
        "    history = model.fit(x_train, y_train, batch_size=batchsize, epochs=n_epochs, verbose=1, validation_data=(x_val, y_val))\n",
        "    plt.plot(history.history['loss'], label='train')\n",
        "    plt.plot(history.history['val_loss'], label='validation')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk8zo-LP6alF"
      },
      "source": [
        "n_in = 672\n",
        "n_out = 144\n",
        "n_features = 1\n",
        "n_val = 1\n",
        "\n",
        "n_epochs = 300\n",
        "batchsize = 128\n",
        "n_neuron = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OzqI5iTAL3x"
      },
      "source": [
        "data = load_data()\n",
        "\n",
        "#data = data[data.Date < '20151231']\n",
        "#values = data.values\n",
        "#plt.figure(figsize=(20,10))\n",
        "#plt.plot(values[:, 0], values[:, 1])\n",
        "#plt.title(data.columns[1], y=0.5, loc='right')\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJR3d2Z9on4L"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data = minmaxscaler(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15NHPZneAih4"
      },
      "source": [
        "data_copy = data.copy()\n",
        "x, y = build_dataset(data_copy)\n",
        "x_train, y_train, x_val, y_val = split_data(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY_jh-oPgP1N"
      },
      "source": [
        "model = build_lstm()\n",
        "model = model_fit(x_train, y_train, x_val, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FguhlLtgHHP"
      },
      "source": [
        "# Validation & visulization\n",
        "predict = model.predict(x_val)\n",
        "validation = scaler.inverse_transform(predict)[0]\n",
        "validation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDorV8pxshjJ"
      },
      "source": [
        "y_val = y_val.reshape(1,n_out)\n",
        "true = scaler.inverse_transform(y_val)[0]\n",
        "true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T32QmZ5VspGI"
      },
      "source": [
        "x = [x for x in range(n_out)]\n",
        "fig, ax = plt.subplots(figsize=(15,5), dpi = 300)\n",
        "ax.plot(x, validation, linewidth=2.0, label = \"predict\")\n",
        "ax.plot(x, true, linewidth=2.0, label = \"true\")\n",
        "ax.legend(loc=2);\n",
        "plt.grid(linestyle='-.')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf0sCsC3w_vO"
      },
      "source": [
        "MSE = mean_squared_error(true,validation)\n",
        "RMSE = np.sqrt(MSE)\n",
        "print('Test RMSE: %.3f' %RMSE)\n",
        "MAE = mean_absolute_error(true,validation)\n",
        "print('Test MAE: %.3f' %MAE)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}